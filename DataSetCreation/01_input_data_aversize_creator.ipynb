{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_xrd(cif=1000000):\n",
    "    return pd.read_csv(cif + '.xy', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../qmof_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking common MOFs in all directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "macro = open('./mofs_macro/control_xy.txt','r')\n",
    "macro = [i.split('.')[0] for i in macro.readlines()]\n",
    "#'''\n",
    "s0050 = open('./mofs_0050nm/control_xy.txt','r')\n",
    "s0050 = ['_'.join(i.split('_')[:2]) for i in s0050.readlines()]\n",
    "#'''\n",
    "s0075 = open('./mofs_0075nm/control_xy.txt','r')\n",
    "s0075 = ['_'.join(i.split('_')[:2]) for i in s0075.readlines()]\n",
    "\n",
    "s0100 = open('./mofs_0100nm/control_xy.txt','r')\n",
    "s0100 = ['_'.join(i.split('_')[:2]) for i in s0100.readlines()]\n",
    "\n",
    "s0250 = open('./mofs_0250nm/control_xy.txt','r')\n",
    "s0250 = ['_'.join(i.split('_')[:2]) for i in s0250.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common1 = np.intersect1d(macro,s0075)\n",
    "common2 = np.intersect1d(s0100,s0250)\n",
    "common3 = np.intersect1d(common1,s0050)\n",
    "\n",
    "common = np.intersect1d(common3, common2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable 'common' enlist the common MOFs in all directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16029,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the common MOFs from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df['name'].isin([i for i in common])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['name', 'info.formula','outputs.pbe.bandgap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsT\nAAALEwEAmpwYAAAQCklEQVR4nO3db6xkdX3H8fdHoLZFWzRsN9tl7SVma4ImBXNDbTAGpSqCKZo0\nBJMiNTbbB9Bga9KuPtE+INk0VWuTlmQFKqZUS0QjKcRKKY3lgeIuRf5K3egadrOwa7WKNdGA3z64\nZ+Owe+/emTt37pnzu+9XcnPP/ObMzPfevfuZ33zPb86kqpAkteVFfRcgSVp/hrskNchwl6QGGe6S\n1CDDXZIadHrfBQCcffbZtbCw0HcZkjQo+/fv/25VbVnuurkI94WFBfbt29d3GZI0KEm+s9J1tmUk\nqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhvsGWth9Fwu77+q7DEmbgOEu\nSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWjXck+xIcl+Sx5M8luT6bvzD\nSQ4neaj7umzkNh9IciDJk0neOssfQJJ0snE+IPs54P1V9WCSlwL7k9zTXfexqvrr0Z2TnAdcBbwa\n+HXg35L8ZlU9v56FS5JWturMvaqOVNWD3fazwBPA9lPc5ArgM1X1k6r6NnAAuHA9ipUkjWeinnuS\nBeAC4Kvd0HVJHk5yS5KXdWPbgadGbnaIUz8ZSJLW2djhnuQlwB3A+6rqh8CNwCuB84EjwEcmeeAk\nu5LsS7Lv2LFjk9xUkrSKscI9yRksBfttVfU5gKp6pqqer6qfAZ/g562Xw8COkZuf0429QFXtrarF\nqlrcsmXLND+DJOkE46yWCXAz8ERVfXRkfNvIbu8EHu227wSuSvLiJOcCO4EH1q9kSdJqxpm5XwRc\nDbzphGWPf5XkkSQPA28E/hSgqh4DbgceB74IXOtKmRfyAzskzdqqSyGr6n4gy1x19ylucwNwwxR1\nSZKm4DtUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnu\nktQgw32DeCZISRvJcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLU\nIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrua5nn0tVkZ7pLUoFXDPcmOJPcleTzJY0mu78ZfnuSe\nJN/svr+sG0+Sv01yIMnDSV476x9CkvRC48zcnwPeX1XnAa8Drk1yHrAbuLeqdgL3dpcB3gbs7L52\nATeue9XSGtii0WayarhX1ZGqerDbfhZ4AtgOXAHc2u12K/CObvsK4FO15CvAWUm2rXfhEiwFtqEt\nnWyinnuSBeAC4KvA1qo60l31NLC1294OPDVys0Pd2In3tSvJviT7jh07NmndkqRTGDvck7wEuAN4\nX1X9cPS6qiqgJnngqtpbVYtVtbhly5ZJbipJWsVY4Z7kDJaC/baq+lw3/Mzxdkv3/Wg3fhjYMXLz\nc7oxSdIGGWe1TICbgSeq6qMjV90JXNNtXwN8YWT83d2qmdcBPxhp30hzw369Wnb6GPtcBFwNPJLk\noW7sg8Ae4PYk7wW+A1zZXXc3cBlwAPgx8J71LFiStLpVw72q7geywtWXLLN/AddOWZc0FWfk2ux8\nh6oGYb1aKLZitFkY7pLUIMNdM+UsWeqH4S5JDTLc1RxfLUjjLYWUBs2w12bkzF2SGuTMfcacNa6v\nhd13cXDP5Stet9b7BFa8X2mInLlLUoMMd0lqkOGuTcl2mVpnuEsjPD2BWmG4a64YrtL6MNwlqUGG\nu7QMXz1o6Ax3SWqQb2KakdVmfr5xZnzOoqXJOXPXXDLQpekY7pLUIMNdc8PZurR+DHcNjmvhpdV5\nQFW9G0JQewBcQ+PMXU0YwhOEtJEMdw3WrAPd9o+GzHBfJ4bA2szT722eapGmZbhLUoMMd60b2xjS\n/DDc15HhJmleGO6S1CDXuWsmfAUj9WvVmXuSW5IcTfLoyNiHkxxO8lD3ddnIdR9IciDJk0neOqvC\nJUkrG6ct80ng0mXGP1ZV53dfdwMkOQ+4Cnh1d5u/T3LaehWrYfJYhLTxVg33qvoy8L0x7+8K4DNV\n9ZOq+jZwALhwivo0QAa51L9pDqhel+Thrm3zsm5sO/DUyD6HurGTJNmVZF+SfceOHZuiDGm2fLLS\nEK013G8EXgmcDxwBPjLpHVTV3qparKrFLVu2rLEMSdJy1hTuVfVMVT1fVT8DPsHPWy+HgR0ju57T\njUkTz4Dt1Utrt6ZwT7Jt5OI7geMrae4Erkry4iTnAjuBB6YrUZI0qVXXuSf5NHAxcHaSQ8CHgIuT\nnA8UcBD4Y4CqeizJ7cDjwHPAtVX1/EwqnxPOLCXNo1XDvaretczwzafY/wbghmmKUvt8UpRmy9MP\nSBPwSUlD4ekHtKEMR2ljOHOXpAYZ7pLUIMN9CrYYJM0rw30GDH1JfTPcJalBhrskNcilkKdwvL1y\ncM/ly45L0rxy5n4CT1YlqQWGuyay0hOfT4jSfDHcV2BYrcxXN9L8s+euqWzGkF/pWIw0T5y5S1KD\nDHdJapDhLkkNMtzHNKuDiJuxZy1p9gx3SWqQ4a4181WHNL8Md0lqkOEuSQ0y3CWpQYa7JDXIcB/h\nAUJJrTDcJalBhnujpn3Tla9ipGEz3CWpQYa7JDXIcJekBq36YR1JbgHeDhytqtd0Yy8H/hlYAA4C\nV1bV95ME+DhwGfBj4A+r6sHZlN6PzdiL3ow/szR048zcPwlcesLYbuDeqtoJ3NtdBngbsLP72gXc\nuD5lts2PrRum0X8z//00b1YN96r6MvC9E4avAG7ttm8F3jEy/qla8hXgrCTb1qlWrRM/5Hq2/D1q\nHqy15761qo50208DW7vt7cBTI/sd6sbm1mb9j7jSqwVfRUhtmPoDsquqktSkt0uyi6XWDa94xSum\nLUNTMMzXzt+d5tVaZ+7PHG+3dN+PduOHgR0j+53TjZ2kqvZW1WJVLW7ZsmWNZWwM/wNLGpq1hvud\nwDXd9jXAF0bG350lrwN+MNK+kSRtkHGWQn4auBg4O8kh4EPAHuD2JO8FvgNc2e1+N0vLIA+wtBTy\nPTOoeVM6/urh4J7LN/wxJQ3PquFeVe9a4apLltm3gGunLWqjbZYQ2yw/pyTfoSpJTTLcJalBhrsk\nNchwb4T9dEmjDPc5MmlAG+jzxXf3ap5M/Q7VoRrCf8I+lj9KasOmmrk7s9JG8W9NfdtU4a6TGUBS\nmzZlW2aeA22cVoy9eUmrceYuSQ0y3OeUs21J0xh8uHvg6uf8XUg6bvDhLkk62aY5oNrqjHa1n6vV\nn1vSqTlzb5CBLslwHwDDWtKkDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMN9YFwWKWkchrsk\nNajJ0w+MnhPdma76dOLfnx+ZqI3S9MzdYJe0WTUd7pK0WRnu0gbynPvaKIa7JDXIcJekBk21WibJ\nQeBZ4HnguapaTPJy4J+BBeAgcGVVfX+6MiVJk1iPmfsbq+r8qlrsLu8G7q2qncC93WVJ0gaaxTr3\nK4CLu+1bgf8A/mIGj3MSD1RJ0pJpZ+4FfCnJ/iS7urGtVXWk234a2LrcDZPsSrIvyb5jx45NWYY0\nLEOYiLiyZ9imnbm/vqoOJ/k14J4k3xi9sqoqSS13w6raC+wFWFxcXHYfSdLaTDVzr6rD3fejwOeB\nC4FnkmwD6L4fnbZISSdzVq1TWXO4JzkzyUuPbwNvAR4F7gSu6Xa7BvjCtEWOwz90tWAWrZDV7tP/\nO22aZua+Fbg/ydeBB4C7quqLwB7gzUm+Cfxud1nSDBnQOtGae+5V9S3gt5YZ/x/gkmmKkiRNx3eo\nSlKDDHdJapDhLjVopYOorl3fPAx3qSejQXuq0J1VGC/3mAZ/Owx3qWezDFTDevMy3CWpQYa7JDVo\nFmeFlDSlhd13cXDP5S+4DLxg7FS3Xcvjner2kzy+5oPhLg3MWvvo9t83F9sy0iY0SdD7pDBMhrs0\nIKudAGzWQWzQD4dtGWnADFutxJm7JDXIcJc0kXHfWat+2ZaR5pShqWk4c5ekBhnuktQgw13Smqz2\nrlb1y3CXtO480No/w12SGmS4S1KDXAopaV2s1oY58UyXmi1n7pLUIGfukmbKA6v9cOYuaWYM9v4Y\n7pLUIMNdkhpkz13ShpmkTePKmuk4c5c0GPbwx2e4Sxo8Q/9kM2vLJLkU+DhwGnBTVe2Z1WNJatNq\nnxk72roZ3XeSlk6rb66aSbgnOQ34O+DNwCHga0nurKrHZ/F4kjaPcWbpx/c5MbQ30wx/Vm2ZC4ED\nVfWtqvop8Bngihk9lqQGjRviq83uJ72/lfYf57FO3Gec/WclVbX+d5r8PnBpVf1Rd/lq4Ler6rqR\nfXYBu7qLrwKeXOPDnQ18d4py+zbk+q29H0OuHYZd/7zV/htVtWW5K3pbCllVe4G9095Pkn1VtbgO\nJfViyPVbez+GXDsMu/4h1T6rtsxhYMfI5XO6MUnSBphVuH8N2Jnk3CS/AFwF3Dmjx5IknWAmbZmq\nei7JdcC/srQU8paqemwWj8U6tHZ6NuT6rb0fQ64dhl3/YGqfyQFVSVK/fIeqJDXIcJekBg063JNc\nmuTJJAeS7O67nkkkuSXJ0SSP9l3LJJLsSHJfkseTPJbk+r5rmkSSX0zyQJKvd/X/Zd81TSrJaUn+\nK8m/9F3LJJIcTPJIkoeS7Ou7nkkkOSvJZ5N8I8kTSX6n75pWM9iee3eKg/9m5BQHwLuGcoqDJG8A\nfgR8qqpe03c940qyDdhWVQ8meSmwH3jHgH7vAc6sqh8lOQO4H7i+qr7Sc2ljS/JnwCLwK1X19r7r\nGVeSg8BiVc3Tm4DGkuRW4D+r6qZuBeAvV9X/9lzWKQ155j7oUxxU1ZeB7/Vdx6Sq6khVPdhtPws8\nAWzvt6rx1ZIfdRfP6L4GM8NJcg5wOXBT37VsFkl+FXgDcDNAVf103oMdhh3u24GnRi4fYkAh04Ik\nC8AFwFd7LmUiXVvjIeAocE9VDan+vwH+HPhZz3WsRQFfSrK/O/3IUJwLHAP+oWuH3ZTkzL6LWs2Q\nw109SvIS4A7gfVX1w77rmURVPV9V57P0zukLkwyiLZbk7cDRqtrfdy1r9Pqqei3wNuDarjU5BKcD\nrwVurKoLgP8D5v4Y35DD3VMc9KTrVd8B3FZVn+u7nrXqXlrfB1zacynjugj4va53/RngTUn+sd+S\nxldVh7vvR4HPs9RaHYJDwKGRV3ifZSns59qQw91THPSgOyB5M/BEVX2073omlWRLkrO67V9i6YD8\nN3otakxV9YGqOqeqFlj6e//3qvqDnssaS5IzuwPwdC2NtwCDWClWVU8DTyV5VTd0CTD3CwgG+wHZ\nG3yKg3WX5NPAxcDZSQ4BH6qqm/utaiwXAVcDj3R9a4APVtXd/ZU0kW3Ard1qqxcBt1fVoJYUDtRW\n4PNLcwNOB/6pqr7Yb0kT+RPgtm4i+S3gPT3Xs6rBLoWUJK1syG0ZSdIKDHdJapDhLkkNMtwlqUGG\nuyQ1yHCXpAYZ7pLUoP8HrSW6esA/rUAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(df['outputs.pbe.bandgap'].values, bins=200)\n",
    "#plt.hlines(y=55, xmin=0, xmax=5, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the input data, the output data and the csv-file in batches of 300 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16029"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(0, 16200, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   300,   600,   900,  1200,  1500,  1800,  2100,  2400,\n",
       "        2700,  3000,  3300,  3600,  3900,  4200,  4500,  4800,  5100,\n",
       "        5400,  5700,  6000,  6300,  6600,  6900,  7200,  7500,  7800,\n",
       "        8100,  8400,  8700,  9000,  9300,  9600,  9900, 10200, 10500,\n",
       "       10800, 11100, 11400, 11700, 12000, 12300, 12600, 12900, 13200,\n",
       "       13500, 13800, 14100, 14400, 14700, 15000, 15300, 15600, 15900])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code can be modified to create the needed data according to the directory in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for first 300 compounds\n",
      "Finished for first 600 compounds\n",
      "Finished for first 900 compounds\n",
      "Finished for first 1200 compounds\n",
      "Finished for first 1500 compounds\n",
      "Finished for first 1800 compounds\n",
      "Finished for first 2100 compounds\n",
      "Finished for first 2400 compounds\n",
      "Finished for first 2700 compounds\n",
      "Finished for first 3000 compounds\n",
      "Finished for first 3300 compounds\n",
      "Finished for first 3600 compounds\n",
      "Finished for first 3900 compounds\n",
      "Finished for first 4200 compounds\n",
      "Finished for first 4500 compounds\n",
      "Finished for first 4800 compounds\n",
      "Finished for first 5100 compounds\n",
      "Finished for first 5400 compounds\n",
      "Finished for first 5700 compounds\n",
      "Finished for first 6000 compounds\n",
      "Finished for first 6300 compounds\n",
      "Finished for first 6600 compounds\n",
      "Finished for first 6900 compounds\n",
      "Finished for first 7200 compounds\n",
      "Finished for first 7500 compounds\n",
      "Finished for first 7800 compounds\n",
      "Finished for first 8100 compounds\n",
      "Finished for first 8400 compounds\n",
      "Finished for first 8700 compounds\n",
      "Finished for first 9000 compounds\n",
      "Finished for first 9300 compounds\n",
      "Finished for first 9600 compounds\n",
      "Finished for first 9900 compounds\n",
      "Finished for first 10200 compounds\n",
      "Finished for first 10500 compounds\n",
      "Finished for first 10800 compounds\n",
      "Finished for first 11100 compounds\n",
      "Finished for first 11400 compounds\n",
      "Finished for first 11700 compounds\n",
      "Finished for first 12000 compounds\n",
      "Finished for first 12300 compounds\n",
      "Finished for first 12600 compounds\n",
      "Finished for first 12900 compounds\n",
      "Finished for first 13200 compounds\n",
      "Finished for first 13500 compounds\n",
      "Finished for first 13800 compounds\n",
      "Finished for first 14100 compounds\n",
      "Finished for first 14400 compounds\n",
      "Finished for first 14700 compounds\n",
      "Finished for first 15000 compounds\n",
      "Finished for first 15300 compounds\n",
      "Finished for first 15600 compounds\n",
      "Finished for first 15900 compounds\n",
      "Finished for first 16200 compounds\n"
     ]
    }
   ],
   "source": [
    "for item in steps:\n",
    "    \n",
    "    df_temp = df_temp = df.iloc[item:(item+300),:].reset_index(drop=True)\n",
    "    \n",
    "    for row in range(df_temp.shape[0]):\n",
    "\n",
    "        xrd = load_xrd(cif='./mofs_0050nm/' + df_temp.iloc[row,0] + '_0050')\n",
    "        input_noise = xrd[1].values/xrd[1].values.max()\n",
    "        noise = 1e-3*np.random.uniform(size=input_data.shape)\n",
    "        input_noise = input_data + noise\n",
    "        q = np.sin(np.deg2rad(xrd[0].values/2))\n",
    "        diff = np.concatenate((input_noise[:,np.newaxis], q[:,np.newaxis]), axis=1)\n",
    "\n",
    "        if row == 0:\n",
    "            diff_stacked = diff[np.newaxis,:,:]\n",
    "        else:\n",
    "            diff_stacked = np.concatenate((diff_stacked, diff[np.newaxis,:,:]), axis = 0)\n",
    "\n",
    "    print('Finished for first', item + 300, 'compounds')\n",
    "    \n",
    "    np.save('./xset_' + str(item) + '_0050', diff_stacked)\n",
    "    np.save('./yset_' + str(item) + '_0050', df_temp['outputs.pbe.bandgap'].values)\n",
    "    df_temp.to_pickle('./dfset_'+str(item)+'_0050.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for first 300 compounds\n",
      "Finished for first 600 compounds\n",
      "Finished for first 900 compounds\n",
      "Finished for first 1200 compounds\n",
      "Finished for first 1500 compounds\n",
      "Finished for first 1800 compounds\n",
      "Finished for first 2100 compounds\n",
      "Finished for first 2400 compounds\n",
      "Finished for first 2700 compounds\n",
      "Finished for first 3000 compounds\n",
      "Finished for first 3300 compounds\n",
      "Finished for first 3600 compounds\n",
      "Finished for first 3900 compounds\n",
      "Finished for first 4200 compounds\n",
      "Finished for first 4500 compounds\n",
      "Finished for first 4800 compounds\n",
      "Finished for first 5100 compounds\n",
      "Finished for first 5400 compounds\n",
      "Finished for first 5700 compounds\n",
      "Finished for first 6000 compounds\n",
      "Finished for first 6300 compounds\n",
      "Finished for first 6600 compounds\n",
      "Finished for first 6900 compounds\n",
      "Finished for first 7200 compounds\n",
      "Finished for first 7500 compounds\n",
      "Finished for first 7800 compounds\n",
      "Finished for first 8100 compounds\n",
      "Finished for first 8400 compounds\n",
      "Finished for first 8700 compounds\n",
      "Finished for first 9000 compounds\n",
      "Finished for first 9300 compounds\n",
      "Finished for first 9600 compounds\n",
      "Finished for first 9900 compounds\n",
      "Finished for first 10200 compounds\n",
      "Finished for first 10500 compounds\n",
      "Finished for first 10800 compounds\n",
      "Finished for first 11100 compounds\n",
      "Finished for first 11400 compounds\n",
      "Finished for first 11700 compounds\n",
      "Finished for first 12000 compounds\n",
      "Finished for first 12300 compounds\n",
      "Finished for first 12600 compounds\n",
      "Finished for first 12900 compounds\n",
      "Finished for first 13200 compounds\n",
      "Finished for first 13500 compounds\n",
      "Finished for first 13800 compounds\n",
      "Finished for first 14100 compounds\n",
      "Finished for first 14400 compounds\n",
      "Finished for first 14700 compounds\n",
      "Finished for first 15000 compounds\n",
      "Finished for first 15300 compounds\n",
      "Finished for first 15600 compounds\n",
      "Finished for first 15900 compounds\n",
      "Finished for first 16200 compounds\n"
     ]
    }
   ],
   "source": [
    "for item in steps:\n",
    "    \n",
    "    df_temp = df_temp = df.iloc[item:(item+300),:].reset_index(drop=True)\n",
    "    \n",
    "    for row in range(df_temp.shape[0]):\n",
    "\n",
    "        xrd = load_xrd(cif='./mofs_0075nm/' + df_temp.iloc[row,0] + '_0075')\n",
    "        input_noise = xrd[1].values/xrd[1].values.max()\n",
    "        noise = 1e-3*np.random.uniform(size=input_data.shape)\n",
    "        input_noise = input_data + noise\n",
    "        q = np.sin(np.deg2rad(xrd[0].values/2))\n",
    "        diff = np.concatenate((input_noise[:,np.newaxis], q[:,np.newaxis]), axis=1)\n",
    "\n",
    "        if row == 0:\n",
    "            diff_stacked = diff[np.newaxis,:,:]\n",
    "        else:\n",
    "            diff_stacked = np.concatenate((diff_stacked, diff[np.newaxis,:,:]), axis = 0)\n",
    "\n",
    "    print('Finished for first', item + 300, 'compounds')\n",
    "    \n",
    "    np.save('./xset_' + str(item) + '_0075', diff_stacked)\n",
    "    np.save('./yset_' + str(item) + '_0075', df_temp['outputs.pbe.bandgap'].values)\n",
    "    df_temp.to_pickle('./dfset_'+str(item)+'_0075.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for first 300 compounds\n",
      "Finished for first 600 compounds\n",
      "Finished for first 900 compounds\n",
      "Finished for first 1200 compounds\n",
      "Finished for first 1500 compounds\n",
      "Finished for first 1800 compounds\n",
      "Finished for first 2100 compounds\n",
      "Finished for first 2400 compounds\n",
      "Finished for first 2700 compounds\n",
      "Finished for first 3000 compounds\n",
      "Finished for first 3300 compounds\n",
      "Finished for first 3600 compounds\n",
      "Finished for first 3900 compounds\n",
      "Finished for first 4200 compounds\n",
      "Finished for first 4500 compounds\n",
      "Finished for first 4800 compounds\n",
      "Finished for first 5100 compounds\n",
      "Finished for first 5400 compounds\n",
      "Finished for first 5700 compounds\n",
      "Finished for first 6000 compounds\n",
      "Finished for first 6300 compounds\n",
      "Finished for first 6600 compounds\n",
      "Finished for first 6900 compounds\n",
      "Finished for first 7200 compounds\n",
      "Finished for first 7500 compounds\n",
      "Finished for first 7800 compounds\n",
      "Finished for first 8100 compounds\n",
      "Finished for first 8400 compounds\n",
      "Finished for first 8700 compounds\n",
      "Finished for first 9000 compounds\n",
      "Finished for first 9300 compounds\n",
      "Finished for first 9600 compounds\n",
      "Finished for first 9900 compounds\n",
      "Finished for first 10200 compounds\n",
      "Finished for first 10500 compounds\n",
      "Finished for first 10800 compounds\n",
      "Finished for first 11100 compounds\n",
      "Finished for first 11400 compounds\n",
      "Finished for first 11700 compounds\n",
      "Finished for first 12000 compounds\n",
      "Finished for first 12300 compounds\n",
      "Finished for first 12600 compounds\n",
      "Finished for first 12900 compounds\n",
      "Finished for first 13200 compounds\n",
      "Finished for first 13500 compounds\n",
      "Finished for first 13800 compounds\n",
      "Finished for first 14100 compounds\n",
      "Finished for first 14400 compounds\n",
      "Finished for first 14700 compounds\n",
      "Finished for first 15000 compounds\n",
      "Finished for first 15300 compounds\n",
      "Finished for first 15600 compounds\n",
      "Finished for first 15900 compounds\n",
      "Finished for first 16200 compounds\n"
     ]
    }
   ],
   "source": [
    "for item in steps:\n",
    "    \n",
    "    df_temp = df_temp = df.iloc[item:(item+300),:].reset_index(drop=True)\n",
    "    \n",
    "    for row in range(df_temp.shape[0]):\n",
    "\n",
    "        xrd = load_xrd(cif='./mofs_0100nm/' + df_temp.iloc[row,0] + '_0100')\n",
    "        input_noise = xrd[1].values/xrd[1].values.max()\n",
    "        noise = 1e-3*np.random.uniform(size=input_data.shape)\n",
    "        input_noise = input_data + noise\n",
    "        q = np.sin(np.deg2rad(xrd[0].values/2))\n",
    "        diff = np.concatenate((input_noise[:,np.newaxis], q[:,np.newaxis]), axis=1)\n",
    "\n",
    "        if row == 0:\n",
    "            diff_stacked = diff[np.newaxis,:,:]\n",
    "        else:\n",
    "            diff_stacked = np.concatenate((diff_stacked, diff[np.newaxis,:,:]), axis = 0)\n",
    "\n",
    "    print('Finished for first', item + 300, 'compounds')\n",
    "    \n",
    "    np.save('./xset_' + str(item) + '_0100', diff_stacked)\n",
    "    np.save('./yset_' + str(item) + '_0100', df_temp['outputs.pbe.bandgap'].values)\n",
    "    df_temp.to_pickle('./dfset_'+str(item)+'_0100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for first 300 compounds\n",
      "Finished for first 600 compounds\n",
      "Finished for first 900 compounds\n",
      "Finished for first 1200 compounds\n",
      "Finished for first 1500 compounds\n",
      "Finished for first 1800 compounds\n",
      "Finished for first 2100 compounds\n",
      "Finished for first 2400 compounds\n",
      "Finished for first 2700 compounds\n",
      "Finished for first 3000 compounds\n",
      "Finished for first 3300 compounds\n",
      "Finished for first 3600 compounds\n",
      "Finished for first 3900 compounds\n",
      "Finished for first 4200 compounds\n",
      "Finished for first 4500 compounds\n",
      "Finished for first 4800 compounds\n",
      "Finished for first 5100 compounds\n",
      "Finished for first 5400 compounds\n",
      "Finished for first 5700 compounds\n",
      "Finished for first 6000 compounds\n",
      "Finished for first 6300 compounds\n",
      "Finished for first 6600 compounds\n",
      "Finished for first 6900 compounds\n",
      "Finished for first 7200 compounds\n",
      "Finished for first 7500 compounds\n",
      "Finished for first 7800 compounds\n",
      "Finished for first 8100 compounds\n",
      "Finished for first 8400 compounds\n",
      "Finished for first 8700 compounds\n",
      "Finished for first 9000 compounds\n",
      "Finished for first 9300 compounds\n",
      "Finished for first 9600 compounds\n",
      "Finished for first 9900 compounds\n",
      "Finished for first 10200 compounds\n",
      "Finished for first 10500 compounds\n",
      "Finished for first 10800 compounds\n",
      "Finished for first 11100 compounds\n",
      "Finished for first 11400 compounds\n",
      "Finished for first 11700 compounds\n",
      "Finished for first 12000 compounds\n",
      "Finished for first 12300 compounds\n",
      "Finished for first 12600 compounds\n",
      "Finished for first 12900 compounds\n",
      "Finished for first 13200 compounds\n",
      "Finished for first 13500 compounds\n",
      "Finished for first 13800 compounds\n",
      "Finished for first 14100 compounds\n",
      "Finished for first 14400 compounds\n",
      "Finished for first 14700 compounds\n",
      "Finished for first 15000 compounds\n",
      "Finished for first 15300 compounds\n",
      "Finished for first 15600 compounds\n",
      "Finished for first 15900 compounds\n",
      "Finished for first 16200 compounds\n"
     ]
    }
   ],
   "source": [
    "for item in steps:\n",
    "    \n",
    "    df_temp = df_temp = df.iloc[item:(item+300),:].reset_index(drop=True)\n",
    "    \n",
    "    for row in range(df_temp.shape[0]):\n",
    "\n",
    "        xrd = load_xrd(cif='./mofs_0250nm/' + df_temp.iloc[row,0] + '_0250')\n",
    "        input_noise = xrd[1].values/xrd[1].values.max()\n",
    "        q = np.sin(np.deg2rad(xrd[0].values/2))\n",
    "        diff = np.concatenate((input_noise[:,np.newaxis], q[:,np.newaxis]), axis=1)\n",
    "\n",
    "        if row == 0:\n",
    "            diff_stacked = diff[np.newaxis,:,:]\n",
    "        else:\n",
    "            diff_stacked = np.concatenate((diff_stacked, diff[np.newaxis,:,:]), axis = 0)\n",
    "\n",
    "    print('Finished for first', item + 300, 'compounds')\n",
    "\n",
    "    np.save('./xset_' + str(item) + '_0250', diff_stacked)\n",
    "    np.save('./yset_' + str(item) + '_0250', df_temp['outputs.pbe.bandgap'].values)\n",
    "    df_temp.to_pickle('./dfset_'+str(item)+'_0250.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for first 300 compounds\n",
      "Finished for first 600 compounds\n",
      "Finished for first 900 compounds\n",
      "Finished for first 1200 compounds\n",
      "Finished for first 1500 compounds\n",
      "Finished for first 1800 compounds\n",
      "Finished for first 2100 compounds\n",
      "Finished for first 2400 compounds\n",
      "Finished for first 2700 compounds\n",
      "Finished for first 3000 compounds\n",
      "Finished for first 3300 compounds\n",
      "Finished for first 3600 compounds\n",
      "Finished for first 3900 compounds\n",
      "Finished for first 4200 compounds\n",
      "Finished for first 4500 compounds\n",
      "Finished for first 4800 compounds\n",
      "Finished for first 5100 compounds\n",
      "Finished for first 5400 compounds\n",
      "Finished for first 5700 compounds\n",
      "Finished for first 6000 compounds\n",
      "Finished for first 6300 compounds\n",
      "Finished for first 6600 compounds\n",
      "Finished for first 6900 compounds\n",
      "Finished for first 7200 compounds\n",
      "Finished for first 7500 compounds\n",
      "Finished for first 7800 compounds\n",
      "Finished for first 8100 compounds\n",
      "Finished for first 8400 compounds\n",
      "Finished for first 8700 compounds\n",
      "Finished for first 9000 compounds\n",
      "Finished for first 9300 compounds\n",
      "Finished for first 9600 compounds\n",
      "Finished for first 9900 compounds\n",
      "Finished for first 10200 compounds\n",
      "Finished for first 10500 compounds\n",
      "Finished for first 10800 compounds\n",
      "Finished for first 11100 compounds\n",
      "Finished for first 11400 compounds\n",
      "Finished for first 11700 compounds\n",
      "Finished for first 12000 compounds\n",
      "Finished for first 12300 compounds\n",
      "Finished for first 12600 compounds\n",
      "Finished for first 12900 compounds\n",
      "Finished for first 13200 compounds\n",
      "Finished for first 13500 compounds\n",
      "Finished for first 13800 compounds\n",
      "Finished for first 14100 compounds\n",
      "Finished for first 14400 compounds\n",
      "Finished for first 14700 compounds\n",
      "Finished for first 15000 compounds\n",
      "Finished for first 15300 compounds\n",
      "Finished for first 15600 compounds\n",
      "Finished for first 15900 compounds\n",
      "Finished for first 16200 compounds\n"
     ]
    }
   ],
   "source": [
    "for item in steps:\n",
    "    \n",
    "    df_temp = df_temp = df.iloc[item:(item+300),:].reset_index(drop=True)\n",
    "    \n",
    "    for row in range(df_temp.shape[0]):\n",
    "\n",
    "        xrd = load_xrd(cif='./mofs_macro/' + df_temp.iloc[row,0])\n",
    "        input_noise = xrd[1].values/xrd[1].values.max()\n",
    "        q = np.sin(np.deg2rad(xrd[0].values/2))\n",
    "        diff = np.concatenate((input_noise[:,np.newaxis], q[:,np.newaxis]), axis=1)\n",
    "\n",
    "        if row == 0:\n",
    "            diff_stacked = diff[np.newaxis,:,:]\n",
    "        else:\n",
    "            diff_stacked = np.concatenate((diff_stacked, diff[np.newaxis,:,:]), axis = 0)\n",
    "\n",
    "    print('Finished for first', item + 300, 'compounds')\n",
    "\n",
    "    np.save('./xset_' + str(item) + '_macro', diff_stacked)\n",
    "    np.save('./yset_' + str(item) + '_macro', df_temp['outputs.pbe.bandgap'].values)\n",
    "    df_temp.to_pickle('./dfset_'+str(item)+'_macro.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
